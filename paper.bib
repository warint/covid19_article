
@article{2020,
  title = {Coronavirus ({{COVID}}-19): Evidence Relevant to Critical Care},
  shorttitle = {Coronavirus ({{COVID}}-19)},
  date = {2020-04-14},
  doi = {SC000039},
  url = {https://www.cochranelibrary.com/collections/doi/SC000039/full},
  urldate = {2020-04-24},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\YB3XYFM4\\full.html},
  langid = {english}
}

@article{abd-alrazaq2020,
  title = {Top {{Concerns}} of {{Tweeters During}} the {{COVID}}-19 {{Pandemic}}: {{Infoveillance Study}}},
  shorttitle = {Top {{Concerns}} of {{Tweeters During}} the {{COVID}}-19 {{Pandemic}}},
  author = {Abd-Alrazaq, Alaa and Alhuwail, Dari and Househ, Mowafa and Hamdi, Mounir and Shah, Zubair},
  date = {2020},
  journaltitle = {Journal of Medical Internet Research},
  volume = {22},
  pages = {e19016},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/19016},
  url = {https://www.jmir.org/2020/4/e19016/},
  urldate = {2020-04-24},
  abstract = {Background:  The recent coronavirus disease (COVID-19) pandemic is taking a toll on the world’s health care infrastructure as well as the social, economic, and psychological well-being of humanity. Individuals, organizations, and governments are using social media to communicate with each other on a number of issues relating to the COVID-19 pandemic. Not much is known about the topics being shared on social media platforms relating to COVID-19. Analyzing such information can help policy makers and health care organizations assess the needs of their stakeholders and address them appropriately.
 Objective:  This study aims to identify the main topics posted by Twitter users related to the COVID-19 pandemic.
 Methods:  Leveraging a set of tools (Twitter’s search application programming interface (API), Tweepy Python library, and PostgreSQL database) and using a set of predefined search terms (“corona,” “2019-nCov,” and “COVID-19”), we extracted the text and metadata (number of likes and retweets, and user profile information including the number of followers) of public English language tweets from February 2, 2020, to March 15, 2020. We analyzed the collected tweets using word frequencies of single (unigrams) and double words (bigrams). We leveraged latent Dirichlet allocation for topic modeling to identify topics discussed in the tweets. We also performed sentiment analysis and extracted the mean number of retweets, likes, and followers for each topic and calculated the interaction rate per topic.
 Results:  Out of approximately 2.8 million tweets included, 167,073 unique tweets from 160,829 unique users met the inclusion criteria. Our analysis identified 12 topics, which were grouped into four main themes: origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating the risk of infection. The mean sentiment was positive for 10 topics and negative for 2 topics (deaths caused by COVID-19 and increased racism). The mean for tweet topics of account followers ranged from 2722 (increased racism) to 13,413 (economic losses). The highest mean of likes for the tweets was 15.4 (economic loss), while the lowest was 3.94 (travel bans and warnings).
 Conclusions:  Public health crisis response activities on the ground and online are becoming increasingly simultaneous and intertwined. Social media provides an opportunity to directly communicate health information to the public. Health systems should work on building national and international disease detection and surveillance systems through monitoring social media. There is also a need for a more proactive and agile public health presence on social media to combat the spread of fake news.
 [J Med Internet Res 2020;22(4):e19016]},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\5UV524LE\\Abd-Alrazaq et al. - 2020 - Top Concerns of Tweeters During the COVID-19 Pande.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\HSTKPEB2\\e19016.html},
  langid = {english},
  number = {4}
}

@article{alberti2019,
  title = {Movecost: {{An R}} Package for Calculating Accumulated Slope-Dependent Anisotropic Cost-Surfaces and Least-Cost Paths},
  shorttitle = {Movecost},
  author = {Alberti, Gianmarco},
  date = {2019-07-01},
  journaltitle = {SoftwareX},
  shortjournal = {SoftwareX},
  volume = {10},
  pages = {100331},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2019.100331},
  url = {http://www.sciencedirect.com/science/article/pii/S2352711019302341},
  urldate = {2019-11-15},
  abstract = {Cost-surface and least-cost path analyses are widely used tools to understand the ways in which movement relates and engages with the surrounding space. They are employed in research fields as diverse as the analysis of travel corridors, land accessibility, site locations, maritime pathways, animal seascape connectivity, transportation, search and rescue operations. This work describes the ‘movecost’ package, designed for the free R statistical environment, which provides the facility to produce, in a relatively straightforward way, various accumulated slope-dependent cost surfaces and least-cost outputs from different models of movement across the terrain. The package motivation and significance are described, and the main software characteristics are outlined by means of an illustrative example.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\88W6WKQ6\\Alberti - 2019 - movecost An R package for calculating accumulated.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\6B7IQ7GH\\S2352711019302341.html},
  keywords = {Cost surface,Geographic information system,Least-cost path,R Package},
  langid = {english}
}

@online{americanstatisticalassociation2018,
  title = {Ethical {{Guidelines}} for {{Statistical Practice}}},
  author = {American Statistical Association},
  date = {2018},
  url = {https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx},
  urldate = {2020-04-30},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\XGXB9T3M\\Ethical-Guidelines-for-Statistical-Practice.html}
}

@article{aria2017b,
  title = {Bibliometrix: {{An R}}-Tool for Comprehensive Science Mapping Analysis},
  shorttitle = {Bibliometrix},
  author = {Aria, Massimo and Cuccurullo, Corrado},
  date = {2017},
  journaltitle = {Journal of Informetrics},
  volume = {11},
  pages = {959--975},
  publisher = {{Elsevier}},
  url = {https://ideas.repec.org/a/eee/infome/v11y2017i4p959-975.html},
  urldate = {2020-04-21},
  abstract = {The use of bibliometrics is gradually extending to all disciplines. It is particularly suitable for science mapping at a time when the emphasis on empirical contributions is producing voluminous, fragmented, and controversial research streams. Science mapping is complex and unwieldly because it is multi-step and frequently requires numerous and diverse software tools, which are not all necessarily freeware. Although automated workflows that integrate these software tools into an organized data flow are emerging, in this paper we propose a unique open-source tool, designed by the authors, called bibliometrix, for performing comprehensive science mapping analysis. bibliometrix supports a recommended workflow to perform bibliometric analyses. As it is programmed in R, the proposed tool is flexible and can be rapidly upgraded and integrated with other statistical R-packages. It is therefore useful in a constantly changing science such as bibliometrics.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\EVYYXMSC\\v11y2017i4p959-975.html},
  keywords = {Bibliographic coupling,Bibliometrics,Co-citation,R package,Science mapping,Workflow},
  langid = {english},
  number = {4}
}

@article{arribas-bel2019,
  title = {A Course on {{Geographic Data Science}}},
  author = {Arribas-Bel, Dani},
  date = {2019-04-26},
  journaltitle = {Journal of Open Source Education},
  volume = {2},
  pages = {42},
  issn = {2577-3569},
  doi = {10.21105/jose.00042},
  url = {https://jose.theoj.org/papers/10.21105/jose.00042},
  urldate = {2020-04-30},
  abstract = {Arribas-Bel, (2019). A course on Geographic Data Science. Journal of Open Source Education, 2(14), 42, https://doi.org/10.21105/jose.00042},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\LBHF54Q9\\Arribas-Bel - 2019 - A course on Geographic Data Science.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\PB8AQJ2C\\jose.html},
  langid = {english},
  number = {16}
}

@inproceedings{avasilcai2018,
  title = {Co-Creators in Innovation Ecosystems. {{Part II}}: {{Crowdsprings}} '{{Crowd}} in Action},
  shorttitle = {Co-Creators in Innovation Ecosystems. {{Part II}}},
  author = {Avasilcai, S. and Galateanu, E.},
  date = {2018},
  volume = {400},
  doi = {10.1088/1757-899X/400/6/062001},
  abstract = {Nowadays the customers changed their roles from co-producers to co-creators as a result of technology disclosure, open innovation acknowledgement and the use of innovation as the main driver for organizational growth. This switch to a complex and adaptive ecosystem became an anchor point for the development of new products, especially within value co-creation processes. From this point of view, the emerging industries are the most relevant for key aspects identification in terms of innovative products and processes, and creativity enhancement. This paper aims to highlight the main features of crowdsourcing implementation within these industries. The research methodology is based on the use of case study approach in order to illustrate how creative companies implement crowdsourcing within their activities. Thus, there will be identified the most relevant features and crowdsourcing activities or processes adopted by the company Crowdspring. A detailed analysis of the platform will reveal how company interacts with their clients or other relevant stakeholders. Also, there will be highlighted the importance of the power of crowd within product development process, starting from the ideation stage. The analysis of creative industries platforms, such as Crowdspring, will reveal the main process of ideas gathering, development and implementation through creative tasks. © Published under licence by IOP Publishing Ltd.},
  eventtitle = {{{IOP Conference Series}}: {{Materials Science}} and {{Engineering}}},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\MJ5A99N3\\Avasilcai and Galateanu - 2018 - Co-creators in innovation ecosystems. Part II Cro.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\AKQ6PUH6\\display.html}
}

@article{cai2019,
  title = {The Power of Crowds: {{Grand}} Challenges in the {{Asia}}-{{Pacific}} Region},
  shorttitle = {The Power of Crowds},
  author = {Cai, C.W. and Gippel, J. and Zhu, Y. and Singh, A.K.},
  date = {2019},
  journaltitle = {Australian Journal of Management},
  volume = {44},
  pages = {551--570},
  doi = {10.1177/0312896219871979},
  abstract = {Technology is enabling organizations across the globe – large and small, for-profit and not-for-profit, governments and scientific groups – to harness the resources, knowledge, talent and creativity of crowds, in their effort to find innovative solutions to vexing problems. As contributors to solving grand challenges, crowds are providing data and funds, generating novel ideas and evaluating and developing concrete solutions. This article proposes a conceptual model for understanding the utility of crowdsourcing in the context of grand challenges. The article further identifies some boundary conditions where crowdsourcing may not be useful and discusses significant barriers to applying crowdsourcing in the Asia-Pacific region. We conclude by recognizing some empirical considerations and avenues for future research. JEL Classification: O31, O35 © The Author(s) 2019.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\WID84VI6\\display.html},
  keywords = {Crowdsourcing,grand challenges,lead users,open innovation},
  number = {4}
}

@article{camacho2020,
  title = {The {{Four Dimensions}} of {{Social Network Analysis}}: {{An Overview}} of {{Research Methods}}, {{Applications}}, and {{Software Tools}}},
  shorttitle = {The {{Four Dimensions}} of {{Social Network Analysis}}},
  author = {Camacho, David and Panizo-LLedot, Àngel and Bello-Orgaz, Gema and Gonzalez-Pardo, Antonio and Cambria, Erik},
  date = {2020-02-21},
  url = {http://arxiv.org/abs/2002.09485},
  urldate = {2020-04-24},
  abstract = {Social network based applications have experienced exponential growth in recent years. One of the reasons for this rise is that this application domain offers a particularly fertile place to test and develop the most advanced computational techniques to extract valuable information from the Web. The main contribution of this work is three-fold: (1) we provide an up-to-date literature review of the state of the art on social network analysis (SNA);(2) we propose a set of new metrics based on four essential features (or dimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of popular SNA tools and frameworks. We have also performed a scientometric study to detect the most active research areas and application domains in this area. This work proposes the definition of four different dimensions, namely Pattern \& Knowledge discovery, Information Fusion \& Integration, Scalability, and Visualization, which are used to define a set of new metrics (termed degrees) in order to evaluate the different software tools and frameworks of SNA (a set of 20 SNA-software tools are analyzed and ranked following previous metrics). These dimensions, together with the defined degrees, allow evaluating and measure the maturity of social network technologies, looking for both a quantitative assessment of them, as to shed light to the challenges and future trends in this active area.},
  archivePrefix = {arXiv},
  eprint = {2002.09485},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\CEIH7U5L\\Camacho et al. - 2020 - The Four Dimensions of Social Network Analysis An.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\7AX4ALV5\\2002.html},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  primaryClass = {cs}
}

@online{centerforsystemsscienceandengineering2020,
  title = {{{COVID}}-19 {{Map}}},
  author = {Center for Systems Science {and} Engineering},
  date = {2020},
  journaltitle = {Johns Hopkins Coronavirus Resource Center},
  url = {https://coronavirus.jhu.edu/map.html},
  urldate = {2020-04-21},
  abstract = {Coronavirus COVID-19 Global Cases by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU)},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\GEZZVZEC\\map.html},
  langid = {english}
}

@online{centersfordiseasecontrolandprevention2020,
  title = {{{COVID}}-19 {{Research Articles Downloadable Database}}},
  author = {Centers for Disease Control {and} Prevention},
  date = {2020-04-23T09:13:13Z},
  url = {https://www.cdc.gov/library/researchguides/2019novelcoronavirus/researcharticles.html},
  urldate = {2020-04-24},
  abstract = {CDC - Stephen B. Thacker Library Branches},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\W8SNNACC\\researcharticles.html},
  langid = {american}
}

@article{chen2020,
  title = {Keep up with the Latest Coronavirus Research},
  author = {Chen, Qingyu and Allot, Alexis and Lu, Zhiyong},
  date = {2020-03-10},
  journaltitle = {Nature},
  volume = {579},
  pages = {193--193},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-020-00694-1},
  url = {https://www.nature.com/articles/d41586-020-00694-1},
  urldate = {2020-04-24},
  abstract = {Discover the world’s best science and medicine  | Nature.com},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\SBD5MRNL\\Chen et al. - 2020 - Keep up with the latest coronavirus research.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\I5QDTRDU\\d41586-020-00694-1.html},
  issue = {7798},
  langid = {english},
  number = {7798}
}

@article{cimoli1995,
  title = {Technological {{Paradigms}}, {{Patterns}} of {{Learning}} and {{Development}}: {{An Introductory Roadmap}}},
  shorttitle = {Technological {{Paradigms}}, {{Patterns}} of {{Learning}} and {{Development}}},
  author = {Cimoli, Mario and Dosi, Giovanni},
  date = {1995},
  journaltitle = {Journal of Evolutionary Economics},
  volume = {5},
  pages = {243--68},
  issn = {1432-1386},
  url = {https://econpapers.repec.org/article/sprjoevec/v_3a5_3ay_3a1995_3ai_3a3_3ap_3a243-68.htm},
  urldate = {2019-12-17},
  abstract = {This paper presents an evolutionary microeconomic theory of innovation and production and discusses its implications for development theory. Using the notions of technological paradigm and trajectory, it develops an alternative view of firm behavior and learning. It is shown then how these are embedded in broader national systems of innovation which account for persistent differences in technological capacities between countries. Finally, this "bottom-up" evolutionary analysis is linked with an institutional "top-down" approach and the potential fruitfulness of this dialogue is demonstrated.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\V4YBNK5Q\\v_3a5_3ay_3a1995_3ai_3a3_3ap_3a243-68.html},
  number = {3}
}

@article{cui2020,
  title = {Manufacturing Big Data Ecosystem: {{A}} Systematic Literature Review},
  shorttitle = {Manufacturing Big Data Ecosystem},
  author = {Cui, Y. and Kara, S. and Chan, K.C.},
  date = {2020},
  journaltitle = {Robotics and Computer-Integrated Manufacturing},
  volume = {62},
  doi = {10.1016/j.rcim.2019.101861},
  abstract = {Advanced manufacturing is one of the core national strategies in the US (AMP), Germany (Industry 4.0) and China (Made-in China 2025). The emergence of the concept of Cyber Physical System (CPS) and big data imperatively enable manufacturing to become smarter and more competitive among nations. Many researchers have proposed new solutions with big data enabling tools for manufacturing applications in three directions: product, production and business. Big data has been a fast-changing research area with many new opportunities for applications in manufacturing. This paper presents a systematic literature review of the state-of-the-art of big data in manufacturing. Six key drivers of big data applications in manufacturing have been identified. The key drivers are system integration, data, prediction, sustainability, resource sharing and hardware. Based on the requirements of manufacturing, nine essential components of big data ecosystem are captured. They are data ingestion, storage, computing, analytics, visualization, management, workflow, infrastructure and security. Several research domains are identified that are driven by available capabilities of big data ecosystem. Five future directions of big data applications in manufacturing are presented from modelling and simulation to real-time big data analytics and cybersecurity. © 2019 Elsevier Ltd},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\4Q96KKGN\\display.html},
  keywords = {Big data,Cloud computing,Cloud manufacturing,Internet of things,NoSQL,Smart manufacturing}
}

@online{davidian2013,
  title = {Aren’t {{We Data Science}}?},
  author = {Davidian, Marie},
  date = {2013},
  journaltitle = {Amstat News},
  url = {https://magazine.amstat.org/blog/2013/07/01/datascience/},
  urldate = {2020-04-30},
  abstract = {ASA's President, Marie Davidian talks about the ASA Big Data initiative with Rachel Schutt.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\6NECQY62\\datascience.html},
  langid = {american}
}

@inproceedings{dec.wang2019,
  title = {A Crowd Science Framework to Support the Construction of a Gold Standard Corpus for Plagiarism Detection},
  author = {De C. Wang, P. and Soares, V.S. and De Souza, J.M. and Esteves, M.G.P. and Schots, N.C.L. and Duarte, F.R.},
  date = {2019},
  pages = {440--445},
  doi = {10.1109/CSCWD.2019.8791853},
  abstract = {The construction of a Gold Standard Corpus for Plagiarism Detection (GSCPD) is a challenging task for reproducible research in computer science, given that there is a trade off between the time expended by the experts and the size, quality, and reliability of a GSCPD. In such a challenging scenario, this paper describes a framework to support the construction of a GSCPD in any language. Aiming for reproducibility and scalability, the framework involves a data acquisition process and a Crowd Science project that employs human processing power to identify plagiarism in pairs of textual data extracted via the data acquisition process. This papers also presents the application of this framework in Portuguese language and the preliminary results of a feasibility study about the use of a tool that composes the framework. © 2019 IEEE.},
  eventtitle = {Proceedings of the 2019 {{IEEE}} 23rd {{International Conference}} on {{Computer Supported Cooperative Work}} in {{Design}}, {{CSCWD}} 2019},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\EILIRNGW\\display.html},
  keywords = {Crowd Science,Crowdsourcing,Gold standard corpus,Plagiarism detection}
}

@software{dowle2019,
  title = {Data.Table: {{Extension}} of 'Data.Frame'},
  shorttitle = {Data.Table},
  author = {Dowle, Matt and Srinivasan, Arun and Gorecki, Jan and Chirico, Michael and Stetsenko, Pasha and Short, Tom and Lianoglou, Steve and Antonyan, Eduard and Bonsch, Markus and Parsonage, Hugh and Ritchie, Scott and Ren, Kun and Tan, Xianying and Saporta, Rick and Seiskari, Otto and Dong, Xianghui and Lang, Michel and Iwasaki, Watal and Wenchel, Seth and Broman, Karl and Schmidt, Tobias and Arenburg, David and Smith, Ethan and Cocquemas, Francois and Gomez, Matthieu and Chataignon, Philippe and Groves, Declan and Possenriede, Daniel and Parages, Felipe and Toth, Denes and Yaramaz-David, Mus and Perumal, Ayappan and Sams, James and Morgan, Martin and Quinn, Michael and @javrucebo and @marc-outins and Storey, Roy and Saraswat, Manish and Jacob, Morgan and Schubmehl, Michael},
  date = {2019-10-18},
  url = {https://CRAN.R-project.org/package=data.table},
  urldate = {2019-11-13},
  abstract = {Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.},
  keywords = {Finance,HighPerformanceComputing},
  version = {1.12.6}
}

@article{duan2020,
  title = {Understanding the Impact of Business Analytics on Innovation},
  author = {Duan, Y. and Cao, G. and Edwards, J.S.},
  date = {2020},
  journaltitle = {European Journal of Operational Research},
  volume = {281},
  pages = {673--686},
  doi = {10.1016/j.ejor.2018.06.021},
  abstract = {Advances in Business Analytics in the era of Big Data have provided unprecedented opportunities for organizations to innovate. With insights gained from Business Analytics, companies are able to develop new or improved products/services. However, few studies have investigated the mechanism through which Business Analytics contributes to a firm's innovation success. This research aims to address this gap by theoretically and empirically investigating the relationship between Business Analytics and innovation. To achieve this aim, absorptive capacity theory is used as a theoretical lens to inform the development of a research model. Absorptive capacity theory refers to a firm's ability to recognize the value of new, external information, assimilate it and apply it to commercial ends. The research model covers the use of Business Analytics, environmental scanning, data-driven culture, innovation (new product newness and meaningfulness), and competitive advantage. The research model is tested through a questionnaire survey of 218 UK businesses. The results suggest that Business Analytics directly improves environmental scanning which in turn helps to enhance a company's innovation. Business Analytics also directly enhances data-driven culture that in turn impacts on environmental scanning. Data-driven culture plays another important role by moderating the effect of environmental scanning on new product meaningfulness. The findings demonstrate the positive impact of business analytics on innovation and the pivotal roles of environmental scanning and data-driven culture. Organizations wishing to realize the potential of Business Analytics thus need changes in both their external and internal focus. © 2018 Elsevier B.V.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\ZN8C27AF\\Duan et al. - 2020 - Understanding the impact of business analytics on .pdf;C\:\\Users\\Thierry\\Zotero\\storage\\WKN62V8V\\display.html},
  keywords = {Absorptive capacity,Analytics,Big Data,Data-driven culture,Innovation},
  number = {3}
}

@article{elhoseny2020,
  title = {Special Issue on Cognitive Big Data Analytics for Business Intelligence Applications: {{Towards}} Performance Improvement},
  shorttitle = {Special Issue on Cognitive Big Data Analytics for Business Intelligence Applications},
  author = {Elhoseny, M. and Kabir Hassan, M. and Kumar Singh, A.},
  date = {2020},
  journaltitle = {International Journal of Information Management},
  volume = {50},
  pages = {413--415},
  doi = {10.1016/j.ijinfomgt.2019.08.004},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\2DDM6HBC\\display.html}
}

@article{ferraris2019,
  title = {Big Data Analytics Capabilities and Knowledge Management: Impact on Firm Performance},
  shorttitle = {Big Data Analytics Capabilities and Knowledge Management},
  author = {Ferraris, A. and Mazzoleni, A. and Devalle, A. and Couturier, J.},
  date = {2019},
  journaltitle = {Management Decision},
  volume = {57},
  pages = {1923--1936},
  doi = {10.1108/MD-07-2018-0825},
  abstract = {Purpose: Big data analytics (BDA) guarantees that data may be analysed and categorised into useful information for businesses and transformed into big data related-knowledge and efficient decision-making processes, thereby improving performance. However, the management of the knowledge generated from the BDA as well as its integration and combination with firm knowledge have scarcely been investigated, despite an emergent need of a structured and integrated approach. The paper aims to discuss these issues. Design/methodology/approach: Through an empirical analysis based on structural equation modelling with data collected from 88 Italian SMEs, the authors tested if BDA capabilities have a positive impact on firm performances, as well as the mediator effect of knowledge management (KM) on this relationship. Findings: The findings of this paper show that firms that developed more BDA capabilities than others, both technological and managerial, increased their performances and that KM orientation plays a significant role in amplifying the effect of BDA capabilities. Originality/value: BDA has the potential to change the way firms compete through better understanding, processing, and exploiting of huge amounts of data coming from different internal and external sources and processes. Some managerial and theoretical implications are proposed and discussed in light of the emergence of this new phenomenon. © 2018, Emerald Publishing Limited.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\8VRGME8G\\display.html},
  keywords = {Big data,Big data analytics,Knowledge management,Performance,SMEs},
  number = {8}
}

@article{gal2019,
  title = {The {{Power}} of the {{Crowd}} in the {{Sharing Economy}}},
  author = {Gal, M.S.},
  date = {2019},
  journaltitle = {Law and Ethics of Human Rights},
  volume = {13},
  pages = {29--59},
  doi = {10.1515/lehr-2019-0002},
  abstract = {Much has been written on the ability of sharing platforms to affect market conditions. In this research we focus on another piece of the puzzle, which is often overlooked but can play a significant role in shaping market structure and conduct: the users of the platform - whether suppliers or consumers (hereinafter jointly or severally: "the crowd"). As will be shown, the power of the crowd can both positively and negatively affect social welfare. Accordingly, this paper seeks to recognize the effects of crowd power and to identify both market-based as well as regulatory solutions to increase its welfare-increasing qualities, while reducing its negative ones. To do so, the study develops in a three stages. The first part explores the welfare effects of the sharing economy on the crowd. This serves as a basis for the second part, which focuses on the role of the crowd in shaping sharing platform markets. The third part then explores the potential role, as well as the limitations, of regulation in ensuring that crowd actions increase welfare. As will be shown, the current legal framework which regulates crowd actions might limit the realization of some of the potential positive effects of social platforms. In particular, new thinking might be needed with regard to rules regulating the use of crowd power to counteract a dominant sharing platform's market power. © 2019 Walter de Gruyter GmbH, Berlin/Boston.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\KIZVIP4S\\display.html},
  keywords = {antitrust,collective action,competition law,crowd,platforms,sharing economy},
  number = {1}
}

@article{ganesan2019,
  title = {Business Intelligence and Advanced Analytics: {{Impact}} and Behavior of Business Decision Making Process},
  shorttitle = {Business Intelligence and Advanced Analytics},
  author = {Ganesan, S. and Gopalsamy, S.},
  date = {2019},
  journaltitle = {International Journal of Recent Technology and Engineering},
  volume = {8},
  pages = {375--379},
  doi = {10.35940/ijrte.C1080.1083S19},
  abstract = {In the current situation, numerous ways are available for the support of leaders, but decision making in an organization are still susceptible to flaws and errors. Among several approaches, Business Intelligence and Advanced Analytics (BI\&AA) is considered a valid tool to managers in the pragmatic decision on the basis of well-informed evidence. In spite of high investment, there is a massive backdrop in this BI\&AA project. Managers have aided with numerous guidelines in making decisions, and those guidelines include information from research works, then things based on guts, and on data that are available. With the help of various experiments, this research has done to investigate whether the information available for decision making affects the mind of the managers or its influence cause change in decision outcome. This research outcome with both descriptive and prescriptive decision theories and further existing literature in the field of BI. As per the result of this research study, remedies are given to improve BI\&AA solutions. © BEIESP.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\MK8YAGE7\\Ganesan and Gopalsamy - 2019 - Business intelligence and advanced analytics Impa.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\DEHKEPML\\display.html},
  issue = {3 Special Issue},
  keywords = {Bigdata,Business intelligence,Data analytics,Decision making}
}

@article{gimenez-bertomeu2019,
  title = {Empirical Evidence for Professional Practice and Public Policies: {{An}} Exploratory Study on Social Exclusion in Users of Primary Care Social Services in {{Spain}}},
  shorttitle = {Empirical Evidence for Professional Practice and Public Policies},
  author = {Giménez‐bertomeu, V.M. and Domenech‐lópez, Y. and Mateo‐pérez, M.A. and De‐alfonseti‐hartmann, N.},
  date = {2019},
  journaltitle = {International Journal of Environmental Research and Public Health},
  volume = {16},
  doi = {10.3390/ijerph16234600},
  abstract = {This study examines the social exclusion characteristics of a sample of users of primary care social services in two local entities in Spain. The objective of this study was to identify the intensity and scope of social exclusion in an exploratory way and to look at the typology of existing exclusionary situations to inform policy making and professional practice. Data from 1009 users were collected by primary care social services professionals, completing the Social Exclusion Scale of the University of Alicante (SES-UA). The dimensions with the greatest levels of social exclusion in the study population were those related to work/employment, income and education and training. The dimensions with an intermediate level of exclusion were those related to housing and social isolation. Social acceptance, family and social conflict and health were the dimensions with the lowest levels of exclusion. The analysis also showed the existence of five significantly different groups, that showed five different life trajectories along the continuum between social exclusion and social inclusion. The results show the importance and utility of developing professional and policy intervention protocols based on research evidence, with the objective of improving the quality of life of the users. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\WI7IBFJQ\\Giménez‐bertomeu et al. - 2019 - Empirical evidence for professional practice and p.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\4YNKSW6Z\\display.html},
  keywords = {Intensity,Policy making,Professional practice,Quality of life,Scope,Social exclusion,Typologies},
  number = {23}
}

@online{governmentofcanada2017,
  title = {The Road to Open Data},
  author = {Government of Canada, Statistics Canada},
  date = {2017-03-09},
  url = {https://www.statcan.gc.ca/eng/blog/cs/open_data},
  urldate = {2019-11-13},
  abstract = {Statistics Canada got its open data report card last week. And, it contains very good news. Open Data Watch ranked Canada 8th among 173 national statistical offices. This is the first year that the organization, based in Washington, D.C., has included......},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\4P5L74DI\\open_data.html},
  langid = {english}
}

@article{hadengue2014,
  title = {Patterns of {{Specialization}} and ({{Un}})Conditional {{Convergence}}: {{The Cases}} of {{Brazil}}, {{China}} and {{India}}},
  shorttitle = {Patterns of {{Specialization}} and ({{Un}})Conditional {{Convergence}}},
  author = {Hadengue, Marine and Warin, Thierry},
  date = {2014},
  journaltitle = {Management international / International Management / Gestiòn Internacional},
  shortjournal = {mi},
  volume = {18},
  pages = {123--141},
  publisher = {{HEC Montréal}},
  issn = {1206-1697, 1918-9222},
  doi = {https://doi.org/10.7202/1027869ar},
  url = {https://www.erudit.org/en/journals/mi/1900-v1-n1-mi01641/1027869ar/abstract/},
  urldate = {2020-04-29},
  abstract = {We propose to measure economic convergence for three emerging countries:        Brazil/China/India. A first result is that the higher the level of productivity in an        industry, the lower its growth rate, showing a convergence to the productivity frontier        represented by the U.S. A first contribution is to propose a new definition of convergence,        based on labor productivity vis-à-vis the technological frontier. A second contribution is        that we use industry-level data to measure convergence. In doing so, we aim to reduce the        biases of using trade data collected at the national level as in previous        models.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\MZQ9VXAY\\Hadengue and Warin - 2014 - Patterns of Specialization and (Un)conditional Con.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\SNB4YRCD\\abstract.html},
  keywords = {Brasil,Brazil,Brésil,China,chine,convergence économique,convergencia económica,crecimiento endógeno,croissance endogène,economic convergence,endogenous growth,Inde,India,labor productivity,productividad del trabajo,productivité du travail},
  langid = {english}
}

@online{hao,
  title = {Over 24,000 Coronavirus Research Papers Are Now Available in One Place},
  author = {Hao, Karen},
  journaltitle = {MIT Technology Review},
  url = {https://www.technologyreview.com/2020/03/16/905290/coronavirus-24000-research-papers-available-open-data/},
  urldate = {2020-04-20},
  abstract = {The news: Today researchers collaborating across several organizations released the Covid-19 Open Research Dataset (CORD-19), which includes over 24,000 research papers from peer-reviewed journals as well as sources like bioRxiv and medRxiv (websites where scientists can post non-peer-reviewed preprint papers). The research covers SARS-CoV-2 (the scientific name for the coronavirus), Covid-19 (the scientific name for…},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\B6TLJFA4\\coronavirus-24000-research-papers-available-open-data.html},
  langid = {english}
}

@article{hartmann2017,
  title = {Linking {{Economic Complexity}}, {{Institutions}}, and {{Income Inequality}}},
  author = {Hartmann, Dominik and Guevara, Miguel R. and Jara-Figueroa, Cristian and Aristarán, Manuel and Hidalgo, César A.},
  date = {2017-05-01},
  journaltitle = {World Development},
  shortjournal = {World Development},
  volume = {93},
  pages = {75--93},
  issn = {0305-750X},
  doi = {10.1016/j.worlddev.2016.12.020},
  url = {http://www.sciencedirect.com/science/article/pii/S0305750X15309876},
  urldate = {2019-12-17},
  abstract = {A country’s mix of products predicts its subsequent pattern of diversification and economic growth. But does this product mix also predict income inequality? Here we combine methods from econometrics, network science, and economic complexity to show that countries exporting complex products—as measured by the Economic Complexity Index—have lower levels of income inequality than countries exporting simpler products. Using multivariate regression analysis, we show that economic complexity is a significant and negative predictor of income inequality and that this relationship is robust to controlling for aggregate measures of income, institutions, export concentration, and human capital. Moreover, we introduce a measure that associates a product to a level of income inequality equal to the average GINI of the countries exporting that product (weighted by the share the product represents in that country’s export basket). We use this measure together with the network of related products—or product space—to illustrate how the development of new products is associated with changes in income inequality. These findings show that economic complexity captures information about an economy’s level of development that is relevant to the ways an economy generates and distributes its income. Moreover, these findings suggest that a country’s productive structure may limit its range of income inequality. Finally, we make our results available through an online resource that allows for its users to visualize the structural transformation of over 150 countries and their associated changes in income inequality during 1963–2008.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\HWIHUVHF\\Hartmann et al. - 2017 - Linking Economic Complexity, Institutions, and Inc.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\8L33AWS8\\S0305750X15309876.html},
  keywords = {economic complexity,economic development,income inequality,institutions,product space},
  langid = {english}
}

@article{hausmann2006,
  title = {Structural {{Transformation}} and {{Patterns}} of {{Comparative Advantage}} in the {{Product Space}}},
  author = {Hausmann, Ricardo and Klinger, Bailey},
  date = {2006},
  journaltitle = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.939646},
  url = {http://www.ssrn.com/abstract=939646},
  urldate = {2018-06-27},
  abstract = {In this paper we examine the product space and its consequences for the process of structural transformation. We argue that the assets and capabilities needed to produce one good are imperfect substitutes for those needed to produce other goods, but the degree of asset specificity varies widely. Given this, the speed of structural transformation will depend on the density of the product space near the area where each country has developed its comparative advantage. While this space is traditionally assumed to be smooth and continuous, we find that in fact it is very heterogeneous, with some areas being very dense and others quite sparse. We develop a measure of revealed proximity between products using comparative advantage in order to map this space, and then show that its heterogeneity is not without consequence. The speed at which countries can transform their productive structure and upgrade their exports depends on having a path to nearby goods that are increasingly of higher value.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\7ZJ8J2PB\\Hausmann et Klinger - 2006 - Structural Transformation and Patterns of Comparat.pdf},
  langid = {english}
}

@book{hausmann2011,
  title = {The {{Atlas}} of {{Economic Complexity}}: {{Mapping}} Paths to {{Prosperity}}},
  shorttitle = {The {{Atlas}} of {{Economic Complexity}}},
  author = {Hausmann, Ricardo and Hidalgo, César A. and Bustos, Sebastián and Coscia, Michele and Chung, Sarah and Jimenez, Juan and Simoes, Alexander and Yıldırım, Muhammed A.},
  date = {2011},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\FZM4UT96\\atlas-economic-complexity-mapping-paths-prosperity-0.html}
}

@book{hausmann2013,
  title = {The {{Atlas}} of {{Economic Complexity}}: {{Mapping Paths}} to {{Prosperity}}},
  shorttitle = {The {{Atlas}} of {{Economic Complexity}}},
  author = {Hausmann, Ricardo and Hidalgo, César A. and Bustos, Sebastian and Coscia, Michele and Simoes, Alexander and Yildirim, Muhammed A.},
  date = {2013},
  publisher = {{MIT Press}},
  location = {{Cambridge}},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\GLWHUF24\\atlas-economic-complexity-mapping-paths-prosperity.html},
  pagetotal = {367}
}

@article{hausmann2014,
  title = {Implied {{Comparative Advantage}}},
  author = {Hausmann, Ricardo and Hidalgo, Cesar and Stock, Daniel P. and Yildirim, Muhammed Ali},
  date = {2014},
  journaltitle = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.2410427},
  url = {http://www.ssrn.com/abstract=2410427},
  urldate = {2018-06-27},
  abstract = {Ricardian theories of production often take the comparative advantage of locations in different industries to be uncorrelated. They are seen as the outcome of the realization of a random extreme value distribution. These theories do not take a stance regarding the counterfactual or implied comparative advantage if the country does not make the product. Here, we find that industries in countries and cities tend to have a relative size that is systematically correlated with that of other industries. Industries also tend to have a relative size that is systematically correlated with the size of the industry in similar countries and cities. We illustrate this using export data for a large set of countries and for city-level data for the US, Chile and India. These stylized facts can be rationalized using a Ricardian framework where comparative advantage is correlated across technologically related industries. More interestingly, the deviations between actual industry intensity and the implied intensity obtained from that of related industries or related locations tend to be highly predictive of future industry growth, especially at horizons of a decade or more. This result holds both at the intensive as well as the extensive margin, indicating that future comparative advantage is already implied in todays pattern of production.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\TWYK6CDQ\\Hausmann et al. - 2014 - Implied Comparative Advantage.pdf},
  langid = {english}
}

@article{haussmann2007,
  title = {The {{Structure}} of the {{Product Space}} and the {{Evolution}} of {{Comparative Advantage}}},
  author = {Haussmann, Ricardo and Klinger, Bailey},
  date = {2007-04},
  journaltitle = {Center for International Development at Harvard University},
  url = {https://growthlab.cid.harvard.edu/files/growthlab/files/146.pdf},
  abstract = {This paper establishes a robust stylized fact: changes in the revealed comparative advantage of nations are governed
by the pattern of relatedness of products at the global level. As countries change their export mix, there is a strong
tendency to move towards related goods rather than to goods that are farther away. The pattern of relatedness of
products is only very partially explained by similarity in broad factor or technological intensities, suggesting that the
relevant determinants are much more product-specific. Moreover, the pattern of relatedness of products exhibits
very strong heterogeneity: there are parts of this ‘product space’ that are dense while others are sparse. This implies
that countries that are specialized in a dense part of the product space have an easier time at changing their revealed
comparative advantage than countries that are specialized in more disconnected products.}
}

@article{hidalgo2009,
  title = {The Building Blocks of Economic Complexity},
  author = {Hidalgo, César A. and Hausmann, Ricardo},
  date = {2009-06-30},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {106},
  pages = {10570--10575},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0900943106},
  url = {https://www.pnas.org/content/106/26/10570},
  urldate = {2019-12-17},
  abstract = {For Adam Smith, wealth was related to the division of labor. As people and firms specialize in different activities, economic efficiency increases, suggesting that development is associated with an increase in the number of individual activities and with the complexity that emerges from the interactions between them. Here we develop a view of economic growth and development that gives a central role to the complexity of a country's economy by interpreting trade data as a bipartite network in which countries are connected to the products they export, and show that it is possible to quantify the complexity of a country's economy by characterizing the structure of this network. Furthermore, we show that the measures of complexity we derive are correlated with a country's level of income, and that deviations from this relationship are predictive of future growth. This suggests that countries tend to converge to the level of income dictated by the complexity of their productive structures, indicating that development efforts should focus on generating the conditions that would allow complexity to emerge to generate sustained growth and prosperity.},
  eprint = {19549871},
  eprinttype = {pmid},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\2Z27X6WR\\Hidalgo and Hausmann - 2009 - The building blocks of economic complexity.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\5X8UVZEI\\10570.html},
  keywords = {economic development,networks},
  langid = {english},
  number = {26}
}

@article{hindle2020,
  title = {Business Analytics: {{Defining}} the Field and Identifying a Research Agenda},
  shorttitle = {Business Analytics},
  author = {Hindle, G. and Kunc, M. and Mortensen, M. and Oztekin, A. and Vidgen, R.},
  date = {2020},
  journaltitle = {European Journal of Operational Research},
  volume = {281},
  pages = {483--490},
  doi = {10.1016/j.ejor.2019.10.001},
  abstract = {The special issue on business analytics has been a great endeavor with more than 100 papers received. The call for papers highlighted that business analytics has a clear role to generate competitive advantage in organizations and our focus has been to demonstrate this role through the papers finally selected for the special issue. The editorial aims to provide not only a summary of the papers but also presents our perspective on the current situation of the field through a computational literature review and comparison with the papers in the special issue. Our findings, and discussions on the papers included in the special issue, suggest that business analytics is maturing as a field with significant synergies and opportunities for the operational research community. © 2019 Elsevier B.V.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\44PD97WI\\display.html},
  keywords = {Business analytics,Computational literature review,Data science,Practice of OR,Topic models},
  number = {3}
}

@book{hirschman1958strategy,
  title = {The Strategy of Economic Development},
  author = {Hirschman, A.O.},
  date = {1958},
  publisher = {{Yale University Press}},
  url = {https://books.google.ca/books?id=wls-AAAAYAAJ},
  lccn = {58011254},
  series = {Yale Paperbound}
}

@article{irizarry2020,
  title = {The {{Role}} of {{Academia}} in {{Data Science Education}}},
  author = {Irizarry, Rafael A.},
  date = {2020},
  journaltitle = {Harvard Data Science Review},
  volume = {2},
  issn = {,},
  doi = {10.1162/99608f92.dd363929},
  url = {https://hdsr.mitpress.mit.edu/pub/gg6swfqh/release/1},
  urldate = {2020-04-30},
  abstract = {As the demand for data scientists continues to grow, universities are trying to figure out how to best contribute to the training of a workforce. However, there does not appear to be a consensus on the fundamental principles, expertise, skills, or knowledge-base needed to define an academic discipline. We argue that data science is not a discipline but rather an umbrella term used to describe a complex process involving not one data scientist possessing all the necessary expertise, but a team of data scientists with nonoverlapping complementary skills. We provide some recommendations for how to take this into account when designing data science academic programs.Keywords: applied statistics, data science, data science curriculum, data wrangling, machine learning, software engineering},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\DUHC7R3M\\Irizarry - The Role of Academia in Data Science Education.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\69UAPJ7I\\1.html},
  langid = {english},
  number = {1}
}

@online{jones2015,
  title = {The {{Identity}} of {{Statistics}} in {{Data Science}}},
  author = {Jones, Tommy},
  date = {2015},
  journaltitle = {Amstat News},
  url = {https://magazine.amstat.org/blog/2015/11/01/statnews2015/},
  urldate = {2020-04-30},
  abstract = {Within the statistics community, there is a debate about whether data science and statistics are distinct disciplines. This conversation about data science betrays an anxiety about our (statisticians’) identity.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\ISGN89MZ\\statnews2015.html},
  langid = {american}
}

@article{joyntmaddox2019,
  title = {Toward {{Evidence}}-{{Based Policy Making}} to {{Reduce Wasteful Health Care Spending}}},
  author = {Joynt Maddox, K.E. and McClellan, M.B.},
  date = {2019},
  journaltitle = {JAMA - Journal of the American Medical Association},
  volume = {322},
  pages = {1460--1462},
  doi = {10.1001/jama.2019.13977},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\5BE66RC2\\display.html},
  number = {15}
}

@article{kim2019,
  title = {{{UTDEventData}}: {{An R}} Package to Access Political Event Data},
  shorttitle = {{{UTDEventData}}},
  author = {Kim, HyoungAh and D’Orazio, Vito and Brandt, Patrick and Looper, Jared and Salam, Sayeed and Khan, Latifur and Shoemate, Michael},
  date = {2019-04-22},
  journaltitle = {Journal of Open Source Software},
  volume = {4},
  pages = {1322},
  issn = {2475-9066},
  doi = {10.21105/joss.01322},
  url = {https://joss.theoj.org/papers/10.21105/joss.01322},
  urldate = {2020-04-29},
  abstract = {Kim et al., (2019). UTDEventData: An R package to access political event data. Journal of Open Source Software, 4(36), 1322, https://doi.org/10.21105/joss.01322},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\4Q3J8LAE\\Kim et al. - 2019 - UTDEventData An R package to access political eve.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\CG2SJU78\\joss.html},
  langid = {english},
  number = {36}
}

@article{kleinberg2003,
  title = {Bursty and {{Hierarchical Structure}} in {{Streams}}},
  author = {Kleinberg, Jon},
  date = {2003-10-01},
  journaltitle = {Data Mining and Knowledge Discovery},
  shortjournal = {Data Mining and Knowledge Discovery},
  volume = {7},
  pages = {373--397},
  issn = {1573-756X},
  doi = {10.1023/A:1024940629314},
  url = {https://doi.org/10.1023/A:1024940629314},
  urldate = {2020-04-24},
  abstract = {A fundamental problem in text data mining is to extract meaningful structure from document streams that arrive continuously over time. E-mail and news articles are two natural examples of such streams, each characterized by topics that appear, grow in intensity for a period of time, and then fade away. The published literature in a particular research field can be seen to exhibit similar phenomena over a much longer time scale. Underlying much of the text mining work in this area is the following intuitive premise—that the appearance of a topic in a document stream is signaled by a “burst of activity,” with certain features rising sharply in frequency as the topic emerges.},
  langid = {english},
  number = {4}
}

@article{marcellis-warin2017,
  title = {A Network Analysis of Financial Conversations on {{Twitter}}},
  author = {Marcellis-Warin, Nathalie De and Sanger, William and Warin, Thierry},
  date = {2017-01-01},
  journaltitle = {International Journal of Web Based Communities},
  shortjournal = {International Journal of Web Based Communities},
  volume = {13},
  pages = {281--310},
  publisher = {{Inderscience Publishers}},
  issn = {1477-8394},
  doi = {10.1504/IJWBC.2017.086588},
  url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJWBC.2017.086588},
  urldate = {2020-04-21},
  abstract = {Assessing influence on social media is at the heart of a new trend in humanities and social sciences. Our paper is about assessing users' influence on social networks. We compare four different methods regarding tweets about financial conversations. We have built two datasets with respectively 489,000 and 280,000 financial tweets. While getting additional followers may provide insight of an increasing popularity, it does not necessarily translate into a more influential position. Our results suggest that the number of followers is only one element of what is considered to be influential. Indeed, the number of messages can be biased by what can be described as 'noisy' users. The number of retweets is a more refined proxy about influence. Finally, the betweenness centrality in the retweet network provides some privileged information to anyone following these users. We compare the performance of stocks mentioned by each type of users. From these results, such methods of assessing influence on Twitter leverage the acquisition of preferential signals in a financial context.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\PGVZDTUL\\IJWBC.2017.html},
  number = {3}
}

@article{meng2019a,
  title = {Data {{Science}}: {{An Artificial Ecosystem}}},
  shorttitle = {Data {{Science}}},
  author = {Meng, Xiao-Li},
  date = {2019},
  journaltitle = {Harvard Data Science Review},
  volume = {1},
  issn = {,},
  doi = {10.1162/99608f92.ba20f892},
  url = {https://hdsr.mitpress.mit.edu/pub/jhy4g6eg/release/6},
  urldate = {2020-04-30},
  abstract = {Issue 1.1},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\TYAR27X5\\Meng - Data Science An Artificial Ecosystem.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\QVSIXI78\\6.html},
  langid = {english},
  number = {1}
}

@article{meng2020,
  title = {Information and {{Uncertainty}}: {{Two Sides}} of the {{Same Coin}}},
  shorttitle = {Information and {{Uncertainty}}},
  author = {Meng, Xiao-Li},
  date = {2020},
  journaltitle = {Harvard Data Science Review},
  doi = {10.1162/99608f92.c108a25b},
  url = {https://hdsr.mitpress.mit.edu/pub/s1mnsz41/release/1},
  urldate = {2020-04-30},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\T59QJVJL\\Meng - Information and Uncertainty Two Sides of the Same.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\IIEMN5Q9\\1.html},
  langid = {english}
}

@article{moyer2020,
  title = {Measuring the {{Gross Domestic Product}} ({{GDP}}): {{The Ultimate Data Science Project}}},
  shorttitle = {Measuring the {{Gross Domestic Product}} ({{GDP}})},
  author = {Moyer, Brian and Dunn, Abe},
  date = {2020},
  journaltitle = {Harvard Data Science Review},
  volume = {2},
  issn = {,},
  doi = {10.1162/99608f92.414caadb},
  url = {https://hdsr.mitpress.mit.edu/pub/5pkkan15/release/1},
  urldate = {2020-04-30},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\45YESMJH\\Moyer and Dunn - Measuring the Gross Domestic Product (GDP) The Ul.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\42F56LDC\\1.html},
  langid = {english},
  number = {1}
}

@article{naur1966,
  title = {The Science of Datalogy ({{Forum}})},
  author = {Naur, Peter},
  date = {1966},
  journaltitle = {Comm. ACM},
  volume = {9},
  pages = {485},
  url = {https://scholar.google.com/scholar?hl=fr&as_sdt=0%2C5&q=+Naur%2C+P.+The+science+of+datalogy+%28Forum%29.+Comm.+ACM+9%2C+7+%28July+1966%29&btnG=},
  urldate = {2020-04-30},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\E5G6CH4N\\scholar.html},
  number = {7}
}

@online{page1999,
  title = {The {{PageRank Citation Ranking}}: {{Bringing Order}} to the {{Web}}.},
  shorttitle = {The {{PageRank Citation Ranking}}},
  author = {Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
  date = {1999-11-11},
  url = {http://ilpubs.stanford.edu:8090/422/},
  urldate = {2019-12-17},
  abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\Z3WHPKNK\\Page et al. - 1999 - The PageRank Citation Ranking Bringing Order to t.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\9THPZB6F\\422.html},
  type = {Techreport}
}

@article{payan2019,
  title = {Use of Research Evidence in State Health Policymaking: {{Menu}} Labeling Policy in {{California}}},
  shorttitle = {Use of Research Evidence in State Health Policymaking},
  author = {Payán, D.D. and Lewis, L.B.},
  date = {2019},
  journaltitle = {Preventive Medicine Reports},
  volume = {16},
  doi = {10.1016/j.pmedr.2019.101004},
  abstract = {Addressing the translational gap between research evidence and state health policy requires an understanding of the current use of research evidence in the state policymaking process. In this study, we explore the use of research evidence to inform the legislative debate about restaurant nutrition labeling policy in California. In 2008, California was the first state to enact a mandatory menu calorie labeling policy in the U.S. Using a qualitative approach, we examine data sources and types of evidence used in legislative documents (n = 87) related to six menu labeling bills introduced in California's state legislature between 2003 and 2008. Federal- and state-level government agency reports were the most frequently cited sources of technical knowledge. Advocacy coalition members who were active participants involved in the policy debate were also cited as experts. Five of the six bills included evidence in related legislative documents. While documents included considerable evidence on the magnitude and severity of the obesity problem to justify policy enactment, there were a limited number of statements referring to policy effectiveness and only one statement identified attesting to implementation context and acceptability. Reference to evidence on related policy suggests policy precedence may also play an important role in policy decision making. There is a need to improve the dissemination of obesity policy effectiveness and implementation studies in a politically time sensitive manner to influence state health policy debates. Strategies are discussed to effectively integrate the use of research evidence in the state health policymaking process. © 2019 The Authors},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\DKWWJG44\\Payán and Lewis - 2019 - Use of research evidence in state health policymak.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\78TDQ5BG\\display.html},
  keywords = {Evidence-based health policy,Menu labeling,Obesity,Qualitative research,State policy}
}

@inproceedings{pulsiri2018,
  title = {Improving {{Systematic Literature Review}} with {{Automation}} and {{Bibliometrics}}},
  author = {Pulsiri, Nonthapat and Vatananan-Thesenvitz, Ronald},
  date = {2018-08-01},
  pages = {1--8},
  doi = {10.23919/PICMET.2018.8481746},
  abstract = {The foundation of a good research paper is the literature review. But with the vast amount of research papers available today it has become more challenging to search and screen for appropriate papers to include in the review. This paper has analyzed different approaches to a literature review and explains the evolution from the traditional literature review to a more modern systematic literature review. The systematic literature review (SLR) can be classified into four key stages: Planning, Conducting, Analysis \& Synthesis, and Reporting. The purpose of this paper is to propose a modified SLR process that includes automation and bibliometrics. Automation is a method that can operationalize the manual tasks of the SLR by using specific tools and computer systems. Bibliometrics is a method to analyze the bibliographic data of published literature to provide an overview of the body of knowledge for a given field of inquiry. The proposed modified SLR process improves the previous versions that rely only on manual search and extraction, by combining the strength of both methods and integrating them into the stages of the SLR process. This addition to the traditional SLR will facilitate the process to produce a faster and more effective Literature review.}
}

@article{quezada-sarmiento2020,
  title = {Body of {{Knowledge Model}} and {{Linked Data Applied}} in {{Development}} of {{Higher Education Curriculum}}},
  author = {Quezada-Sarmiento, P.A. and Enciso, L. and Conde, L. and Mayorga-Diaz, M.P. and Guaigua-Vizcaino, M.E. and Hernandez, W. and Washizaki, H.},
  date = {2020},
  journaltitle = {Advances in Intelligent Systems and Computing},
  volume = {943},
  pages = {758--773},
  doi = {10.1007/978-3-030-17795-9_57},
  abstract = {The corpus of knowledge or Bodies of Knowledge (BOK) term was used to describe a set of structures than codify all concept, terms, techniques, and sustainable educational activities that constitute the domain of the exercise of a profession or specific area of knowledge. This is the reason why it is important for both the scientific and the educational communities to carry out research in BOK. In short, BOK proposes new strategies that allow to describe, represent, and combine the above-mentioned set of structures with different computational techniques. One of these techniques is Linked Data, which appeared in the Web Semantic Context. This paper describes the study and implementation of Linked Data Technologies for the publication of data related to the academic offer of a Higher Education Center, using a methodology of publication of Linked Data and supported by the model of description of BOK. From the process described above, a web application was obtained, where the BOK model and principles of the were combined, for the visualization of academic data, as a contribution to curricular development. The next steps are implemented of BOK model with the combination of other semantic web techniques and artificial intelligence principles. © 2020, Springer Nature Switzerland AG.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\HLTLW9KG\\display.html},
  keywords = {Bodies of Knowledge,Curriculum,Education,Linked Data,Semantic Web}
}

@article{rialti2019,
  title = {Big Data and Dynamic Capabilities: A Bibliometric Analysis and Systematic Literature Review},
  shorttitle = {Big Data and Dynamic Capabilities},
  author = {Rialti, R. and Marzi, G. and Ciappei, C. and Busso, D.},
  date = {2019},
  journaltitle = {Management Decision},
  volume = {57},
  pages = {2052--2068},
  doi = {10.1108/MD-07-2018-0821},
  abstract = {Purpose: Recently, several manuscripts about the effects of big data on organizations used dynamic capabilities as their main theoretical approach. However, these manuscripts still lack systematization. Consequently, the purpose of this paper is to systematize the literature on big data and dynamic capabilities. Design/methodology/approach: A bibliometric analysis was performed on 170 manuscripts extracted from the Clarivate Analytics Web of Science Core Collection database. The bibliometric analysis was integrated with a literature review. Findings: The bibliometric analysis revealed four clusters of papers on big data and dynamic capabilities: big data and supply chain management, knowledge management, decision making, business process management and big data analytics. The systematic literature review helped to clarify each clusters’ content. Originality/value: To the authors’ best knowledge, minimal attention has been paid to systematizing the literature on big data and dynamic capabilities. © 2019, Emerald Publishing Limited.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\T5R8LCBS\\Rialti et al. - 2019 - Big data and dynamic capabilities a bibliometric .pdf;C\:\\Users\\Thierry\\Zotero\\storage\\XG2PW8A8\\display.html},
  keywords = {Bibliometric analysis,Big data,Big data analytics,Dynamic capabilities,Performance,Systematic literature review},
  number = {8}
}

@article{robert2016,
  title = {Complexity Paths in Neo-{{Schumpeterian}} Evolutionary Economics, Structural Change and Development Policies},
  author = {Robert, Verónica and Yoguel, Gabriel},
  date = {2016-09-01},
  journaltitle = {Structural Change and Economic Dynamics},
  shortjournal = {Structural Change and Economic Dynamics},
  volume = {38},
  pages = {3--14},
  issn = {0954-349X},
  doi = {10.1016/j.strueco.2015.11.004},
  url = {http://www.sciencedirect.com/science/article/pii/S0954349X15000624},
  urldate = {2019-12-17},
  abstract = {Recently, several authors of evolutionary and neo-Schumpeterian economics have identified in complex systems a common framework for accounting for a range of attributes they have been claiming are present in economic systems: path-dependence, positive feedbacks, micro-heterogeneity, emergent properties, and self-organization. Complexity seems to be broad enough to accommodate very different positions and it has been seen as a unifying approach for evolutionary and neo-Schumpeterian streams. This pluralism is reflected in the fact that many authors that draw upon complexity ideas from neo-Schumpeterian evolutionary theory, make contrasting policy recommendations in terms of if it should be vertical or horizontal or if it should promote bottom-up process or direct interventions. This is possible because the complexity approach has not yet been fully developed and its limits are still somewhat blurred. In this paper, we propose to explore this idea by identifying the theoretical backgrounds and the policy recommendations of different groups of neo-Schumpeterian evolutionary authors. We propose that backgrounds focused on different attributes of complexity lead to different development policies recommendations.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\RCNR2U4X\\Robert and Yoguel - 2016 - Complexity paths in neo-Schumpeterian evolutionary.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\8QFH579D\\S0954349X15000624.html},
  keywords = {Complexity,Development policies,Evolutionary and neo-Schumpeterian economics,Structural change},
  langid = {english},
  series = {Complexity and {{Economic Development}}}
}

@article{samuelsen2019,
  title = {Integrating Multiple Data Sources for Learning Analytics—Review of Literature},
  author = {Samuelsen, J. and Chen, W. and Wasson, B.},
  date = {2019},
  journaltitle = {Research and Practice in Technology Enhanced Learning},
  volume = {14},
  doi = {10.1186/s41039-019-0105-4},
  abstract = {Learning analytics (LA) promises understanding and optimization of learning and learning environments. To enable richer insights regarding questions related to learning and education, LA solutions should be able to integrate data coming from many different data sources, which may be stored in different formats and have varying levels of structure. Data integration also plays a role for the scalability of LA, an important challenge in itself. The objective of this review is to assess the current state of LA in terms of data integration in the context of higher education. The initial search of six academic databases and common venues for publishing LA research resulted in 115 publications, out of which 20 were included in the final analysis. The results show that a few data sources (e.g., LMS) appear repeatedly in the research studies; the number of data sources used in LA studies in higher education tends to be limited; when data are integrated, similar data formats are often combined (a low-hanging fruit in terms of technical challenges); the research literature tends to lack details about data integration in the implemented systems; and, despite being a good starting point for data integration, educational data specifications (e.g., xAPI) seem to seldom be used. In addition, the results indicate a lack of stakeholder (e.g., teachers/instructors, technology vendors) involvement in the research studies. The review concludes by offering recommendations to address limitations and gaps in the research reported in the literature. © 2019, The Author(s).},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\SCNBF6WM\\Samuelsen et al. - 2019 - Integrating multiple data sources for learning ana.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\L9CGV8UN\\display.html},
  keywords = {Data integration,Higher education,Interoperability,Learning analytics,Multiple data sources,Scalability},
  number = {1}
}

@online{scholar,
  title = {{{CORD}}-19 | {{Semantic Scholar}}},
  author = {Scholar, Semantic},
  url = {https://pages.semanticscholar.org/coronavirus-research},
  urldate = {2020-04-21},
  abstract = {CORD-19 (COVID-19 Open Research Dataset) is a free resource of over 44,000 scholarly articles about COVID-19 and related coronaviruses.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\EH8FP6DP\\coronavirus-research.html},
  langid = {english}
}

@online{socialprogress2020,
  title = {2019 {{Social Progress Index}}},
  author = {Social Progress},
  date = {2020},
  url = {https://www.socialprogress.org/},
  urldate = {2020-04-29},
  abstract = {We provide decision-makers and everyday citizens with the very best data on the social and environmental health of their societies and help them prioritize actions that accelerate social progress.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\2N2IIM95\\0.html},
  langid = {english}
}

@article{tacchella2012,
  title = {A {{New Metrics}} for {{Countries}}' {{Fitness}} and {{Products}}' {{Complexity}}},
  author = {Tacchella, Andrea and Cristelli, Matthieu and Caldarelli, Guido and Gabrielli, Andrea and Pietronero, Luciano},
  date = {2012-10-10},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {2},
  pages = {1--7},
  issn = {2045-2322},
  doi = {10.1038/srep00723},
  url = {https://www.nature.com/articles/srep00723},
  urldate = {2019-12-17},
  abstract = {Classical economic theories prescribe specialization of countries industrial production. Inspection of the country databases of exported products shows that this is not the case: successful countries are extremely diversified, in analogy with biosystems evolving in a competitive dynamical environment. The challenge is assessing quantitatively the non-monetary competitive advantage of diversification which represents the hidden potential for development and growth. Here we develop a new statistical approach based on coupled non-linear maps, whose fixed point defines a new metrics for the country Fitness and product Complexity. We show that a non-linear iteration is necessary to bound the complexity of products by the fitness of the less competitive countries exporting them. We show that, given the paradigm of economic complexity, the correct and simplest approach to measure the competitiveness of countries is the one presented in this work. Furthermore our metrics appears to be economically well-grounded.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\L8V6ERVP\\Tacchella et al. - 2012 - A New Metrics for Countries' Fitness and Products'.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\R74SW5AA\\srep00723.html},
  langid = {english},
  number = {1}
}

@article{tani2018,
  title = {The {{System Thinking Perspective}} in the {{Open}}-{{Innovation Research}}: {{A Systematic Review}}},
  shorttitle = {The {{System Thinking Perspective}} in the {{Open}}-{{Innovation Research}}},
  author = {Tani, Mario and Papaluca, Ornella and Sasso, Pasquale},
  date = {2018-09},
  journaltitle = {Journal of Open Innovation: Technology, Market, and Complexity},
  volume = {4},
  pages = {38},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/joitmc4030038},
  url = {https://www.mdpi.com/2199-8531/4/3/38},
  urldate = {2020-04-24},
  abstract = {The new logics of competitions are mostly based on exploiting relationships to implement new mechanisms in managing Knowledge. Today, a successful company should be, lean, modular, and with a smart approach to new products development. In this context, the source of competitive advantage cannot be found into a static heterogeneity of resources, but companies must be able to create and manage a dynamic competitive process to continuously reinvent their products/services and to re-combine their resources with their partners’ ones. A paradigm for this behavior is the Open Innovation one, as created by Chesbrough. According to the rules of this paradigm, companies have to acknowledge that they operate in a network of relationships, they must be open to cooperate with their external partners, and they must not try to limit their actions in reaching only for some pre-defined result. So, Open Innovation Networks appear to be similar to those described by the scholars in the Complex Adaptive Systems field where the actions of the system, and of its parts, are the result of the various actors’ interactions in an emergent way. In this paper, we use a Systematic Literature Review approach to explore how the main topics in the System Thinking Perspective, and in particular, those related to Complex Systems, are linked to the Open Innovation studies.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\VQXSKINV\\Tani et al. - 2018 - The System Thinking Perspective in the Open-Innova.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\EFDI6G7D\\38.html},
  issue = {3},
  keywords = {Complex Systems,innovation,interactions,Open Innovation,resource-based theory,system thinking,systematic literature review},
  langid = {english},
  number = {3}
}

@article{teece1994,
  title = {Understanding Corporate Coherence: {{Theory}} and Evidence},
  shorttitle = {Understanding Corporate Coherence},
  author = {Teece, David J. and Rumelt, Richard and Dosi, Giovanni and Winter, Sidney},
  date = {1994-01-01},
  journaltitle = {Journal of Economic Behavior \& Organization},
  shortjournal = {Journal of Economic Behavior \& Organization},
  volume = {23},
  pages = {1--30},
  issn = {0167-2681},
  doi = {10.1016/0167-2681(94)90094-9},
  url = {http://www.sciencedirect.com/science/article/pii/0167268194900949},
  urldate = {2019-12-17},
  abstract = {Multiproduct firms are perceived to be coherent in their scope, yet there is no strong theoretical foundations to explain coherence in modern industrial organization theory. This paper shows that as U.S. manufacturing firms grow more diverse, they maintain a constant level of coherence between neighboring activities. This finding runs counter to the idea that firms with many activities are generally more ‘incoherent’. A framework is then presented which appeals to the nature of enterprise learning, path dependencies, and the nature of the selection environment to explain the ubiquity of coherent diversifiers.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\CPTS95YU\\0167268194900949.html},
  langid = {english},
  number = {1}
}

@article{utkovski2018,
  title = {Economic Complexity Unfolded: {{Interpretable}} Model for the Productive Structure of Economies},
  shorttitle = {Economic Complexity Unfolded},
  author = {Utkovski, Zoran and Pradier, Melanie F. and Stojkoski, Viktor and Perez-Cruz, Fernando and Kocarev, Ljupco},
  date = {2018-08-07},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {13},
  pages = {e0200822},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0200822},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0200822},
  urldate = {2019-12-17},
  abstract = {Economic complexity reflects the amount of knowledge that is embedded in the productive structure of an economy. It resides on the premise of hidden capabilities—fundamental endowments underlying the productive structure. In general, measuring the capabilities behind economic complexity directly is difficult, and indirect measures have been suggested which exploit the fact that the presence of the capabilities is expressed in a country’s mix of products. We complement these studies by introducing a probabilistic framework which leverages Bayesian non-parametric techniques to extract the dominant features behind the comparative advantage in exported products. Based on economic evidence and trade data, we place a restricted Indian Buffet Process on the distribution of countries’ capability endowment, appealing to a culinary metaphor to model the process of capability acquisition. The approach comes with a unique level of interpretability, as it produces a concise and economically plausible description of the instantiated capabilities.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\JH2ZG4ZA\\Utkovski et al. - 2018 - Economic complexity unfolded Interpretable model .pdf;C\:\\Users\\Thierry\\Zotero\\storage\\FA7SBGC4\\article.html},
  keywords = {Chile (country),Economic development,Economic geography,Economics,Egypt,Fiber metallurgy,Indonesia,Vegetables},
  langid = {english},
  number = {8}
}

@article{vanrijmenam2019,
  title = {Avoid Being the {{Turkey}}: {{How}} Big Data Analytics Changes the Game of Strategy in Times of Ambiguity and Uncertainty},
  shorttitle = {Avoid Being the {{Turkey}}},
  author = {van Rijmenam, M. and Erekhinskaya, T. and Schweitzer, J. and Williams, M.-A.},
  date = {2019},
  journaltitle = {Long Range Planning},
  volume = {52},
  doi = {10.1016/j.lrp.2018.05.007},
  abstract = {In order for organisations to remain competitive in times of ambiguity and uncertainty, there is a need to detect and anticipate unknown unknowns, also called ‘black swans’. When these are ignored they may lead to competitive struggles. In this paper, we build on this view and suggest that big data analytics can provide necessary insights to help change strategy making. Research suggests that ambidextrous organisations should focus on developing and maintaining their dynamic capabilities. Following on from this, we take a dynamic capabilities perspective and propose a theoretical framework to explain the intricacies of big data analytics. This framework explains the ability of organisations to detect, anticipate and respond strategically in ambiguous and uncertain business environments. For a meta-synthesis of 101 cases of big data analytics, we employ a multi-method approach that incorporates Natural Language Processing, semantic analysis and case analysis, allowing extraction and analysis of structured information from unstructured data. Overall, we find evidence of big data analytics helping to detect, anticipate and respond to industry disruption. We offer six propositions about the relationships between the levels of data analytics capabilities and strategic dynamic capabilities. We find that descriptive data analytics improves the capability of an organisation to understand the business context (sensing) and that predictive data analytics aids in the realisation of business opportunities (seizing). This study contributes to an understanding of big data analytics as a dynamic organisational capability that supports strategic decision-making in times of ambiguity and uncertainty. We conclude by suggesting areas for further investigation, particularly in regard to the strategic application of prescriptive data analytics. © 2018 Elsevier Ltd},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\H9YHKAI2\\display.html},
  keywords = {Big data,Data analytics,Dynamic capabilities,Strategy},
  number = {5},
  options = {useprefix=true}
}

@article{vargas2020,
  title = {Economiccomplexity: {{Computational Methods}} for {{Economic Complexity}}},
  shorttitle = {Economiccomplexity},
  author = {Vargas, Mauricio},
  date = {2020-02-19},
  journaltitle = {Journal of Open Source Software},
  volume = {5},
  pages = {1866},
  issn = {2475-9066},
  doi = {10.21105/joss.01866},
  url = {https://joss.theoj.org/papers/10.21105/joss.01866},
  urldate = {2020-04-29},
  abstract = {Vargas, (2020). Economiccomplexity: Computational Methods for Economic Complexity. Journal of Open Source Software, 5(46), 1866, https://doi.org/10.21105/joss.01866},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\QIHRTMP6\\Vargas - 2020 - Economiccomplexity Computational Methods for Econ.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\46V5XC9Q\\joss.html},
  langid = {english},
  number = {46}
}

@article{vidgen2020,
  title = {Exploring the Ethical Implications of Business Analytics with a Business Ethics Canvas},
  author = {Vidgen, R. and Hindle, G. and Randolph, I.},
  date = {2020},
  journaltitle = {European Journal of Operational Research},
  volume = {281},
  pages = {491--501},
  doi = {10.1016/j.ejor.2019.04.036},
  abstract = {The ethical aspects of data science and artificial intelligence have become a major issue. Organisations that deploy data scientists and operational researchers (OR) must address the ethical implications of their use of data and algorithms. We review the OR and data science literature on ethics and find that this work is pitched at the level of guiding principles and frameworks and fails to provide a practical and grounded approach that can be used by practitioners as part of the analytics development process. Further, given the advent of the General Data Protection Regulation (GDPR) an ethical dimension is likely to become an increasingly important aspect of analytics development. Drawing on the business analytics methodology (BAM) developed by Hindle and Vidgen (2018) we tackle this challenge through action research with a pseudonymous online travel company, EuroTravel. The method that emerges uses an opportunity canvas and a business ethics canvas to explore value creation and ethical aspects jointly. The business ethics canvas draws on the Markkula Center's five ethical principles (utility, rights, justice, common good, and virtue) to which explicit consideration of stakeholders is added. A contribution of the paper is to show how an ethical dimension can be embedded in the everyday exploration of analytics development opportunities, as distinct from a stand-alone ethical decision-making tool or as an overlay of a general set of guiding principles. We also propose that value and ethics should not be viewed as separate entities, rather they should be seen as inseparable and intertwined. © 2019 Elsevier B.V.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\LQK9W28K\\display.html},
  keywords = {Business analytics,Business ethics canvas,Data science,GDPR,Markkula},
  number = {3}
}

@article{villumsen2019,
  title = {Development and Progression in {{Danish eHealth}} Policies: {{Towards}} Evidence-Based Policy Making},
  shorttitle = {Development and Progression in {{Danish eHealth}} Policies},
  author = {Villumsen, S. and Faxvaag, A. and Nøhr, C.},
  date = {2019},
  journaltitle = {Studies in Health Technology and Informatics},
  volume = {264},
  pages = {1075--1079},
  doi = {10.3233/SHTI190390},
  abstract = {In order to realise the potential benefits of eHealth, governments develop eHealth policies to define and prioritise initiatives, the strategic goals and the resulting benefits. During the 23 years with eHealth policies in Denmark only a few status reports with a systematic and transparent evaluation have been made. This paper advocates a more systematic approach to strategic planning of development and implementation of eHealth systems, by encouraging the concept of evidence-based policy making through analysis of how focus of the Danish eHealth policies have evolved. The Danish eHealth policies have very different framings following the different focus points for the policies. Interestingly, strategies for evaluating the devolopment of eHealth and eHealth policies were very sparcely noted in the policies. For the first time the de-emphasising of evaluations of eHealth policies in Denmark has been empirically demonstrated, thus undermining the objective of obtaining evidence-based eHealth policies. © 2019 International Medical Informatics Association (IMIA) and IOS Press.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\ETJPY7IB\\display.html},
  keywords = {Learning,Medical Informatics,Policy}
}

@article{wang2020,
  title = {A Novel Coronavirus Outbreak of Global Health Concern},
  author = {Wang, Chen and Horby, Peter W. and Hayden, Frederick G. and Gao, George F.},
  date = {2020-02-15},
  journaltitle = {The Lancet},
  shortjournal = {The Lancet},
  volume = {395},
  pages = {470--473},
  publisher = {{Elsevier}},
  issn = {0140-6736, 1474-547X},
  doi = {10.1016/S0140-6736(20)30185-9},
  url = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)30185-9/abstract},
  urldate = {2020-04-21},
  abstract = {In December, 2019, Wuhan, Hubei province, China, became the centre of an outbreak
of pneumonia of unknown cause, which raised intense attention not only within China
but internationally. Chinese health authorities did an immediate investigation to
characterise and control the disease, including isolation of people suspected to have
the disease, close monitoring of contacts, epidemiological and clinical data collection
from patients, and development of diagnostic and treatment procedures. By Jan 7, 2020,
Chinese scientists had isolated a novel coronavirus (CoV) from patients in Wuhan.},
  eprint = {31986257},
  eprinttype = {pmid},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\4TRHTLVZ\\Wang et al. - 2020 - A novel coronavirus outbreak of global health conc.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\YXNKNLJS\\fulltext.html},
  langid = {english},
  number = {10223}
}

@report{warin2007,
  title = {An {{Empirical Study}} of {{Price Dispersion}} in {{Homogenous Goods Markets}}},
  author = {Warin, Thierry and Leiter, Daniel B.},
  date = {2007-09},
  journaltitle = {Middlebury College Working Paper Series},
  institution = {{Middlebury College, Department of Economics}},
  url = {https://ideas.repec.org/p/mdl/mdlpap/0710.html},
  urldate = {2020-04-18},
  abstract = {This paper presents the results of an empirical study of price dispersion in homogeneous goods markets. Modern economic theory suggests that inevitable asymmetries of information in markets lead to an equilibrium in which price dispersion is present even when goods are perfectly homogenous. In this paper we present an empirical analysis in which we employ both cross-sectional and time-series data gathered directly from Pricegrabber.com, one of the most popular and comprehensive online shopping/price-comparison sites on the Internet. In particular our analysis focuses on (i) the effect that the number of firms offering a good has on price dispersion, (ii) the informational value to the consumer of using the Pricegrabber website, and (iii) the persistency of price dispersion over time.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\H38GQ4IE\\Warin and Leiter - 2007 - An Empirical Study of Price Dispersion in Homogeno.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\EZH99UFC\\0710.html},
  keywords = {E-commerce,Gatekeepers,Internet marketing,L11,L86,Price dispersion,Regression and other statistical techniques JEL Classification: L81,Search Cost,Signaling},
  langid = {english},
  number = {0710},
  series = {Middlebury {{College Working Paper Series}}}
}

@article{warin2012,
  title = {Homogenous Goods Markets: An Empirical Study of Price Dispersion on the Internet},
  shorttitle = {Homogenous Goods Markets},
  author = {Warin, Thierry and Leiter, Daniel},
  date = {2012-01-01},
  journaltitle = {International Journal of Economics and Business Research},
  shortjournal = {International Journal of Economics and Business Research},
  volume = {4},
  pages = {514--529},
  publisher = {{Inderscience Publishers}},
  issn = {1756-9850},
  doi = {10.1504/IJEBR.2012.048776},
  url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJEBR.2012.048776},
  urldate = {2020-04-18},
  abstract = {This paper presents the results of an empirical study of price dispersion in homogenous goods markets. Modern economic theory suggests that markets will inevitably have information asymmetries resulting in equilibriums with price dispersion even when goods are perfectly homogenous. Earlier studies have tried to explain price dispersion in online markets using variables not related to information: seller characteristics, market competitiveness and time of entry. Our study enhances the previous literature by focusing exclusively on information. In this paper, we employ both cross-sectional and time series data gathered directly from},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\ZAZ4DN2P\\IJEBR.2012.html},
  number = {5}
}

@inproceedings{warin2017,
  title = {Mapping {{Innovations}} in {{Artificial Intelligence}} through {{Patents}}: {{A Social Data Science Perspective}}},
  shorttitle = {Mapping {{Innovations}} in {{Artificial Intelligence}} through {{Patents}}},
  booktitle = {2017 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  author = {Warin, Thierry and Duc, Romain Le and Sanger, William},
  date = {2017-12},
  pages = {252--257},
  doi = {10.1109/CSCI.2017.40},
  abstract = {This paper is about mapping innovations in Artificial Intelligence (AI) with the help of patents. It leverages the use of Social Data Science techniques on two levels: (1) we perform a content analysis of all the abstracts of the available patents of an extensive database; (2) we use a Latent Dirichlet Allocation (LDA) technique on these patents' abstracts to extract which categories best describe each subfield of AI. Our goal is to have a deeper perspective and a deeper understanding of the various developments in AI through time and geography. The database used in this paper is one of the most comprehensive, with a total of 55,109 patents. To contextualize this study, the literature review uses information from 29,225 articles. In both cases, the analysis of such amount of information could not be possible without dedicated computing power.},
  eventtitle = {2017 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\GBHFD9YW\\8560795.html},
  keywords = {artificial intelligence,content analysis,data analysis,Data Mining,Innovation,innovation management,latent Dirichlet allocation technique,LDA,mapping innovations,patents,Patents,Social Data Science,social data science perspective,social data science techniques,social sciences computing,statistical analysis}
}

@article{warin2018a,
  title = {Connectivity and Closeness among International Financial Institutions: A Network Theory Perspective},
  shorttitle = {Connectivity and Closeness among International Financial Institutions},
  author = {Warin, Thierry and Sanger, William},
  date = {2018-01-01},
  journaltitle = {International Journal of Comparative Management},
  shortjournal = {International Journal of Comparative Management},
  volume = {1},
  pages = {225--254},
  publisher = {{Inderscience Publishers}},
  issn = {2514-4111},
  doi = {10.1504/IJCM.2018.094479},
  url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJCM.2018.094479},
  urldate = {2020-04-21},
  abstract = {This article focuses on connectivity and closeness between financial institutions. Financial institutions are a subset of multinational corporations and play an important role in our modern economies. By studying connectivity and closeness, this article proposes a network theory approach to the notion of systemic risk. Using network theory, we propose to look at potential networks between financial institutions through their boards of directors. Measures of centrality (degree, closeness, betweenness, eigenvalue) and force-directed networks are provided for each country. We built a large sample (43,399 individuals; 2,209 institutions) across 52 countries using Bureau van Dijk's database. We find corporate interlocks showing - to some degree - the level of concentration within the financial system. The main contribution of this article is to show some evidence of small-world properties of the international financial system; the ramifications of this question could be critical, notably in terms of systemic risk.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\LFG6J5AB\\IJCM.2018.html},
  number = {3}
}

@article{warin2020e,
  title = {Hacking {{Health Covid}}-19},
  author = {Warin, Thierry},
  date = {2020},
  doi = {DOI 10.6084/m9.figshare.12020994.v2},
  url = {https://www.warin.ca/simulation/hackingHealthCovid.html},
  urldate = {2020-05-01},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\6S5VX9VY\\hackingHealthCovid.html}
}

@article{wing2019,
  title = {The {{Data Life Cycle}}},
  author = {Wing, Jeannette M.},
  date = {2019-05-30},
  journaltitle = {Harvard Data Science Review},
  volume = {1},
  publisher = {{PubPub}},
  issn = {,},
  doi = {10.1162/99608f92.e26845b4},
  url = {https://hdsr.mitpress.mit.edu/pub/577rq08d/release/3},
  urldate = {2020-04-30},
  abstract = {To put data science in context, we present phases of the data life cycle, from data generation to data interpretation. These phases transform raw bits into value for the end user. Data science is thus much more than data analysis, e.g., using techniques from machine learning and statistics; extracting this value takes a lot of work, before and after data analysis. Moreover, data privacy and data ethics need to be considered at each phase of the life cycle.Keywordsanalysis, collection, data life cycle, ethics, generation, interpretation, management, privacy, storage, story-telling, visualization},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\H2XSYEG8\\Wing - 2019 - The Data Life Cycle.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\MM87QLTU\\3.html},
  langid = {english},
  number = {1}
}

@article{wolffe2019,
  title = {Systematic Evidence Maps as a Novel Tool to Support Evidence-Based Decision-Making in Chemicals Policy and Risk Management},
  author = {Wolffe, T.A.M. and Whaley, P. and Halsall, C. and Rooney, A.A. and Walker, V.R.},
  date = {2019},
  journaltitle = {Environment International},
  volume = {130},
  doi = {10.1016/j.envint.2019.05.065},
  abstract = {Background: While systematic review (SR) methods are gaining traction as a method for providing a reliable summary of existing evidence for health risks posed by exposure to chemical substances, it is becoming clear that their value is restricted to a specific range of risk management scenarios - in particular, those which can be addressed with tightly focused questions and can accommodate the time and resource requirements of a systematic evidence synthesis. Methods: The concept of a systematic evidence map (SEM) is defined and contrasted to the function and limitations of systematic review (SR) in the context of risk management decision-making. The potential for SEMs to facilitate evidence-based decision-making are explored using a hypothetical example in risk management priority-setting. The potential role of SEMs in reference to broader risk management workflows is characterised. Results: SEMs are databases of systematically gathered research which characterise broad features of the evidence base. Although not intended to substitute for the evidence synthesis element of systematic reviews, SEMs provide a comprehensive, queryable summary of a large body of policy relevant research. They provide an evidence-based approach to characterising the extent of available evidence and support forward looking predictions or trendspotting in the chemical risk sciences. In particular, SEMs facilitate the identification of related bodies of decision critical chemical risk information which could be further analysed using SR methods, and highlight gaps in the evidence which could be addressed with additional primary studies to reduce uncertainties in decision-making. Conclusions: SEMs have strong and growing potential as a high value tool in resource efficient use of existing research in chemical risk management. They can be used as a critical precursor to efficient deployment of high quality SR methods for characterising chemical health risks. Furthermore, SEMs have potential, at a large scale, to support the sort of evidence summarisation and surveillance methods which would greatly increase the resource efficiency, transparency and effectiveness of regulatory initiatives such as EU REACH and US TSCA. © 2019 The Authors},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\T6DIVEMD\\Wolffe et al. - 2019 - Systematic evidence maps as a novel tool to suppor.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\8S7JQZB9\\display.html},
  keywords = {Evidence mapping,Systematic review}
}

@online{worldhealthorganization2020,
  title = {Global Research on Coronavirus Disease ({{COVID}}-19)},
  author = {World Health Organization},
  date = {2020},
  url = {https://www.who.int/emergencies/diseases/novel-coronavirus-2019/global-research-on-novel-coronavirus-2019-ncov},
  urldate = {2020-04-24},
  abstract = {Repository of latest international multilingual scientific findings and knowledge on COVID-19.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\WH99SGN6\\global-research-on-novel-coronavirus-2019-ncov.html},
  langid = {english}
}

@article{wu2020,
  title = {Open-Source Analytics Tools for Studying the {{COVID}}-19 Coronavirus Outbreak},
  author = {Wu, Tianzhi and Ge, Xijin and Yu, Guangchuang and Hu, Erqiang},
  date = {2020-03-05},
  journaltitle = {medRxiv},
  pages = {2020.02.25.20027433},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  doi = {10.1101/2020.02.25.20027433},
  url = {https://www.medrxiv.org/content/10.1101/2020.02.25.20027433v2},
  urldate = {2020-04-21},
  abstract = {{$<$}p{$>$}To provide convenient access to epidemiological data on the coronavirus outbreak, we developed an R package, nCov2019 (https://github.com/GuangchuangYu/nCov2019). Besides detailed real-time statistics, it offers access to three data sources with detailed daily statistics from December 1, 2019, for 43 countries and more than 500 Chinese cities. We also developed a web app (http://www.bcloud.org/e/) with interactive plots and simple time-series forecasts. These analytics tools could be useful in informing the public and studying how this and similar viruses spread in populous countries.{$<$}/p{$>$}},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\SEALZNCX\\Wu et al. - 2020 - Open-source analytics tools for studying the COVID.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\5IQGAIHZ\\2020.02.25.html},
  langid = {english}
}

@article{zhao2019,
  title = {Mapping the {{Knowledge Domain}} of {{Smart}}-{{City Research}}: {{A Bibliometric}} and {{Scientometric Analysis}}},
  shorttitle = {Mapping the {{Knowledge Domain}} of {{Smart}}-{{City Research}}},
  author = {Zhao, Li and Tang, Zhi-ying and Zou, Xin},
  date = {2019-01},
  journaltitle = {Sustainability},
  volume = {11},
  pages = {6648},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/su11236648},
  url = {https://www.mdpi.com/2071-1050/11/23/6648},
  urldate = {2020-04-24},
  abstract = {As urbanization continues to accelerate, the number of cities and their growing populations have created problems, such as the congestion and noise related to transportation, the pollution from industry, and the difficulty of disposing of garbage. An emerging urban strategy is to make use of digital technologies and big data to help improve the quality of life of urban residents. In the past decade, more and more researchers have studied smart cities, and the number of literature in this field grows rapidly, making it \&ldquo;big data\&rdquo;. With the aim of better understanding the contexts of smart-city research, including the distribution of topics, knowledge bases, and the research frontiers in the field, this paper is based on the Science Citation Index Expanded (SCIE) and Social Sciences Citation Index (SSCI) in the Web of Science (WoS) Core Collection, and the method used is that of comprehensive scientometric analysis and knowledge mapping in terms of diversity, time slicing, and dynamics, using VOSviewer and CiteSpace to study the literature in the field. The main research topics can be divided into three areas\&mdash;\&ldquo;the concepts and elements of the smart city\&rdquo;, \&ldquo;the smart city and the Internet of Things\&rdquo;, and \&ldquo;the smart city of the future\&rdquo;\&mdash;through document co-citation analysis. There are four key directions\&mdash;\&ldquo;research objectives and development-strategy research\&rdquo;, \&ldquo;technical-support research\&rdquo;, \&ldquo;data-processing and applied research\&rdquo;, and \&ldquo;management and applied research\&rdquo;\&mdash;analyzed using keywords co-occurrence. Finally, the research frontiers are urban-development, sustainable cities, cloud computing, artificial intelligence, integration, undertaken through keyword co-occurrence analysis.},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\B9AE6HNP\\Zhao et al. - 2019 - Mapping the Knowledge Domain of Smart-City Researc.pdf;C\:\\Users\\Thierry\\Zotero\\storage\\A7WKZPBY\\htm.html},
  issue = {23},
  keywords = {CiteSpace,Scientometrics,Smart city,Visualization,VOSviewer},
  langid = {english},
  number = {23}
}

@online{zotero-81668,
  title = {Scopus - {{Document}} Search Results},
  url = {https://www-scopus-com.ezp.skema.edu/results/results.uri?numberOfFields=0&src=s&clickedLink=&edit=&editSaveSearch=&origin=searchbasic&authorTab=&affiliationTab=&advancedTab=&scint=1&menu=search&tablin=&searchterm1=evidence+based+policy+making&field1=TITLE_ABS_KEY&dateType=Publication_Date_Type&yearFrom=Before+1960&yearTo=Present&loadDate=7&documenttype=All&accessTypes=All&resetFormLink=&st1=evidence+based+policy+making&st2=&sot=b&sdt=b&sl=43&s=TITLE-ABS-KEY%28evidence+based+policy+making%29&sid=365377d43cc2bc0949f47779817b3448&searchId=365377d43cc2bc0949f47779817b3448&txGid=6cda9857f87dbc96c9c0b4cecc84e446&sort=plf-f&originationType=b&rr=},
  urldate = {2019-12-03},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\7MKLKGSF\\results.html}
}

@online{zotero-81810,
  title = {{{CEPII}} - {{BACI}} - {{Papers}}},
  url = {http://www.cepii.fr/CEPII/en/bdd_modele/papers.asp?id=1#sthash.vF5O0Ruh.dpuf},
  urldate = {2018-06-27},
  file = {C\:\\Users\\Thierry\\Zotero\\storage\\TSCIHKS2\\papers.html}
}


